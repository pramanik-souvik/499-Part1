{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "753d41bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q&A dataset saved to processed_bengali_qa.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the processed CSV\n",
    "file_path = \"sData/df_temp.csv\"  # Adjust if needed\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Function to generate 5 Bengali Q&A pairs from a given text\n",
    "def generate_qa_pairs(text):\n",
    "    questions = [\n",
    "        \"এই লেখার মূল বিষয়বস্তু কী?\",\n",
    "        \"এতে কী ঐতিহাসিক ঘটনা বর্ণনা করা হয়েছে?\",\n",
    "        \"লেখাটি কোন সময়কাল নিয়ে আলোচনা করে?\",\n",
    "        \"এতে উল্লেখযোগ্য ব্যক্তি বা ঘটনাবলি কী কী?\",\n",
    "        \"এর প্রেক্ষাপট কী ছিল?\"\n",
    "    ]\n",
    "    qa_pairs = [{\"question\": q, \"answer\": text.strip()} for q in questions]\n",
    "    return qa_pairs\n",
    "\n",
    "# List to hold final Q&A dataset\n",
    "qa_data = []\n",
    "\n",
    "# Iterate through each row to generate Q&A\n",
    "for idx, row in df.iterrows():\n",
    "    source_text = str(row[\"content\"]).strip()\n",
    "    \n",
    "    # Skip very short content\n",
    "    if len(source_text) < 50 or pd.isna(source_text):\n",
    "        continue\n",
    "\n",
    "    qa_pairs = generate_qa_pairs(source_text)\n",
    "    for qa in qa_pairs:\n",
    "        qa_data.append({\n",
    "            \"id\": idx + 1,\n",
    "            \"type\": row[\"type\"],\n",
    "            \"content\": source_text,\n",
    "            \"question\": qa[\"question\"],\n",
    "            \"answer\": qa[\"answer\"]\n",
    "        })\n",
    "\n",
    "# Create final Q&A DataFrame\n",
    "qa_df = pd.DataFrame(qa_data)\n",
    "\n",
    "# Save to CSV\n",
    "output_file = \"processed_bengali_qa.csv\"\n",
    "qa_df.to_csv(output_file, index=False)\n",
    "print(f\"Q&A dataset saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93a2847e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USERAS\\anaconda3\\envs\\resPy\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Device set to use cuda:0\n",
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q&A dataset saved to bengali_qa.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline, T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Load the processed CSV\n",
    "file_path = \"sData/temp2.csv\"  # Update path if needed\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Load BanglaT5 model for Q&A generation\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"csebuetnlp/banglat5_banglaparaphrase\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"csebuetnlp/banglat5_banglaparaphrase\")\n",
    "\n",
    "# Initialize pipeline\n",
    "qa_generator = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Function to generate a Q&A pair from content\n",
    "def generate_qa_pairs_llm(text):\n",
    "    try:\n",
    "        text = text.strip()\n",
    "        if len(text) < 50:\n",
    "            return []\n",
    "\n",
    "        # Generate a question\n",
    "        question_input = f\"এই পাঠ্যাংশ থেকে একটি প্রশ্ন তৈরি করো: {text}\"\n",
    "        questions = qa_generator(question_input, max_length=100, num_return_sequences=1)\n",
    "\n",
    "        # Generate answer for the question\n",
    "        question = questions[0]['generated_text'].strip()\n",
    "        answer_input = f\"প্রশ্ন: {question}। এই লেখার ভিত্তিতে উত্তর দাও: {text}\"\n",
    "        answers = qa_generator(answer_input, max_length=200, num_return_sequences=1)\n",
    "\n",
    "        answer = answers[0]['generated_text'].strip()\n",
    "\n",
    "        return [{\"question\": question, \"answer\": answer}]\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        return []\n",
    "\n",
    "# List to collect Q&A data\n",
    "qa_data = []\n",
    "\n",
    "# Process each row\n",
    "for idx, row in df.iterrows():\n",
    "    content = str(row[\"content\"]).strip()\n",
    "    if not content or len(content) < 50:\n",
    "        continue\n",
    "\n",
    "    qa_pairs = generate_qa_pairs_llm(content)\n",
    "    for qa in qa_pairs:\n",
    "        qa_data.append({\n",
    "            \"id\": idx + 1,\n",
    "            \"type\": row[\"type\"],\n",
    "            \"content\": content,\n",
    "            \"question\": qa[\"question\"],\n",
    "            \"answer\": qa[\"answer\"]\n",
    "        })\n",
    "\n",
    "# Create DataFrame and save\n",
    "qa_df = pd.DataFrame(qa_data)\n",
    "output_file = \"bengali_qa.csv\"\n",
    "qa_df.to_csv(output_file, index=False)\n",
    "print(f\"Q&A dataset saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d6e5e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (535 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bengali LLM Q&A dataset saved to: bengali_llm_qa_output.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline, T5ForConditionalGeneration, T5Tokenizer\n",
    "import random\n",
    "\n",
    "# Load the processed CSV (must have 'type' and 'content' columns)\n",
    "file_path = \"sData/temp2.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Load BanglaT5 model for Q&A generation\n",
    "model_name = \"csebuetnlp/banglat5_banglaparaphrase\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Initialize pipeline\n",
    "qa_generator = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device=0)\n",
    "\n",
    "# Function to generate Q&A pairs using LLM\n",
    "def generate_qa_pairs_llm(text, num_questions=3):\n",
    "    try:\n",
    "        text = text.strip()\n",
    "        if len(text) < 50:\n",
    "            return []\n",
    "\n",
    "        qa_pairs = []\n",
    "\n",
    "        for _ in range(num_questions):\n",
    "            # Randomly alter prompt wording\n",
    "            prompt_options = [\n",
    "                f\"এই লেখার ভিত্তিতে একটি প্রশ্ন তৈরি করো: {text}\",\n",
    "                f\"এই অনুচ্ছেদ থেকে প্রশ্ন তৈরি করো: {text}\",\n",
    "                f\"এই পাঠ্যাংশ অনুসারে একটি প্রশ্ন দাও: {text}\"\n",
    "            ]\n",
    "            question_input = random.choice(prompt_options)\n",
    "\n",
    "            # Generate a question\n",
    "            questions = qa_generator(question_input, max_length=50, num_return_sequences=1)\n",
    "            question = questions[0]['generated_text'].strip()\n",
    "\n",
    "            if not question or len(question.split()) < 2:\n",
    "                continue\n",
    "\n",
    "            # Generate answer\n",
    "            answer_input = f\"প্রশ্ন: {question}। এই লেখার ভিত্তিতে সংক্ষেপে উত্তর দাও: {text}\"\n",
    "            answers = qa_generator(answer_input, max_length=50, num_return_sequences=1)\n",
    "            answer = answers[0]['generated_text'].strip()\n",
    "\n",
    "            if not answer or answer.lower() in text.lower():\n",
    "                continue  # Avoid copying from content\n",
    "\n",
    "            # Keep short answers\n",
    "            if len(answer.split()) > 20:\n",
    "                continue\n",
    "\n",
    "            qa_pairs.append({\"question\": question, \"answer\": answer})\n",
    "\n",
    "        return qa_pairs\n",
    "    except Exception as e:\n",
    "        print(f\"Error on text: {e}\")\n",
    "        return []\n",
    "\n",
    "# Collect generated Q&A data\n",
    "qa_data = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    content = str(row[\"content\"]).strip()\n",
    "    if not content:\n",
    "        continue\n",
    "\n",
    "    qa_pairs = generate_qa_pairs_llm(content)\n",
    "\n",
    "    if not qa_pairs:\n",
    "        # Add a null row if no valid Q&A found\n",
    "        qa_data.append({\n",
    "            \"id\": idx + 1,\n",
    "            \"type\": row[\"type\"],\n",
    "            \"content\": content,\n",
    "            \"question\": None,\n",
    "            \"answer\": None\n",
    "        })\n",
    "    else:\n",
    "        for qa in qa_pairs:\n",
    "            qa_data.append({\n",
    "                \"id\": idx + 1,\n",
    "                \"type\": row[\"type\"],\n",
    "                \"content\": content,\n",
    "                \"question\": qa[\"question\"],\n",
    "                \"answer\": qa[\"answer\"]\n",
    "            })\n",
    "\n",
    "# Save results\n",
    "qa_df = pd.DataFrame(qa_data)\n",
    "output_file = \"bengali_llm_qa_output.csv\"\n",
    "qa_df.to_csv(output_file, index=False)\n",
    "print(f\"Bengali LLM Q&A dataset saved to: {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resPy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
